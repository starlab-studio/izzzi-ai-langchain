"""Initial migration

Revision ID: 2ab3c373f88f
Revises: 
Create Date: 2026-01-02 14:14:27.399180

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import pgvector.sqlalchemy

# revision identifiers, used by Alembic.
revision: str = '2ab3c373f88f'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # Create pgvector extension if it doesn't exist
    # NOTE: pgvector must be installed on the PostgreSQL server first
    # For Docker: use image pgvector/pgvector:pg14 (or pg15, pg16)
    # For local: install via package manager (brew install pgvector, apt-get install postgresql-14-pgvector, etc.)
    try:
        op.execute('CREATE EXTENSION IF NOT EXISTS vector')
    except Exception as e:
        # If extension is not available, provide helpful error message
        if 'is not available' in str(e):
            raise Exception(
                "pgvector extension is not installed on the PostgreSQL server. "
                "Please install it first:\n"
                "- Docker: use image 'pgvector/pgvector:pg14' (or pg15, pg16)\n"
                "- macOS: brew install pgvector\n"
                "- Ubuntu/Debian: apt-get install postgresql-14-pgvector\n"
                "Then retry the migration."
            ) from e
        raise
    
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('analysis_cache',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('cache_key', sa.String(length=255), nullable=False),
    sa.Column('cache_value', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('expires_at', sa.TIMESTAMP(), nullable=False),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_analysis_cache_cache_key'), 'analysis_cache', ['cache_key'], unique=True)
    op.create_index(op.f('ix_analysis_cache_expires_at'), 'analysis_cache', ['expires_at'], unique=False)
    op.create_table('chatbot_conversations',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('organization_id', sa.UUID(), nullable=False),
    sa.Column('subject_id', sa.UUID(), nullable=True),
    sa.Column('query', sa.Text(), nullable=False),
    sa.Column('response', sa.Text(), nullable=False),
    sa.Column('sources', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_chatbot_conversations_user_id'), 'chatbot_conversations', ['user_id'], unique=False)
    op.create_table('insights',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('subject_id', sa.UUID(), nullable=False),
    sa.Column('organization_id', sa.UUID(), nullable=False),
    sa.Column('insight_type', sa.String(length=50), nullable=False),
    sa.Column('title', sa.String(length=255), nullable=False),
    sa.Column('content', sa.Text(), nullable=False),
    sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True),
    sa.Column('evidence', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=True),
    sa.Column('priority', sa.String(length=20), nullable=True),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_insights_organization_id'), 'insights', ['organization_id'], unique=False)
    op.create_index(op.f('ix_insights_subject_id'), 'insights', ['subject_id'], unique=False)
    op.create_table('response_embeddings',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('response_id', sa.UUID(), nullable=False),
    sa.Column('answer_id', sa.UUID(), nullable=True),
    sa.Column('text_content', sa.Text(), nullable=False),
    sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_response_embeddings_response_id'), 'response_embeddings', ['response_id'], unique=False)
    op.create_table('subject_analyses',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('subject_id', sa.UUID(), nullable=False),
    sa.Column('organization_id', sa.UUID(), nullable=False),
    sa.Column('analysis_type', sa.String(length=50), nullable=False),
    sa.Column('period_start', sa.TIMESTAMP(), nullable=False),
    sa.Column('period_end', sa.TIMESTAMP(), nullable=False),
    sa.Column('result', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_by_user_id', sa.UUID(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_subject_analyses_analysis_type'), 'subject_analyses', ['analysis_type'], unique=False)
    op.create_index(op.f('ix_subject_analyses_organization_id'), 'subject_analyses', ['organization_id'], unique=False)
    op.create_index(op.f('ix_subject_analyses_subject_id'), 'subject_analyses', ['subject_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # Drop pgvector extension (optional - comment out if you want to keep it)
    # op.execute('DROP EXTENSION IF EXISTS vector')
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_subject_analyses_subject_id'), table_name='subject_analyses')
    op.drop_index(op.f('ix_subject_analyses_organization_id'), table_name='subject_analyses')
    op.drop_index(op.f('ix_subject_analyses_analysis_type'), table_name='subject_analyses')
    op.drop_table('subject_analyses')
    op.drop_index(op.f('ix_response_embeddings_response_id'), table_name='response_embeddings')
    op.drop_table('response_embeddings')
    op.drop_index(op.f('ix_insights_subject_id'), table_name='insights')
    op.drop_index(op.f('ix_insights_organization_id'), table_name='insights')
    op.drop_table('insights')
    op.drop_index(op.f('ix_chatbot_conversations_user_id'), table_name='chatbot_conversations')
    op.drop_table('chatbot_conversations')
    op.drop_index(op.f('ix_analysis_cache_expires_at'), table_name='analysis_cache')
    op.drop_index(op.f('ix_analysis_cache_cache_key'), table_name='analysis_cache')
    op.drop_table('analysis_cache')
    # ### end Alembic commands ###
