# Izzzi AI Analysis Service

Microservice d'analyse IA des retours √©l√®ves utilisant LangChain, OpenAI et pgvector pour fournir des analyses de sentiment, des insights, des alertes et des rapports automatis√©s.

## üìã Table des mati√®res

- [Description](#description)
- [Architecture](#architecture)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Pr√©requis](#pr√©requis)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [API Endpoints](#api-endpoints)
- [Jobs Celery](#jobs-celery)
- [Migrations](#migrations)
- [D√©veloppement](#d√©veloppement)
- [Docker](#docker)

## üéØ Description

Le service Izzzi AI Analysis est un microservice FastAPI qui analyse les retours des √©l√®ves pour g√©n√©rer :

- **Analyses de sentiment** : Score global et distribution positive/neutre/n√©gative
- **Insights complets** : Th√®mes r√©currents, points d'attention, recommandations
- **Alertes IA** : D√©tection automatique de probl√®mes n√©cessitant une action
- **R√©sum√©s de feedback** : Synth√®ses textuelles g√©n√©r√©es par LLM
- **Recherche s√©mantique** : Recherche vectorielle dans les r√©ponses des √©l√®ves
- **Chatbot intelligent** : Agent LangChain pour r√©pondre aux questions des enseignants
- **Rapports hebdomadaires** : G√©n√©ration automatique de rapports pour chaque organisation

## üèóÔ∏è Architecture

Le projet suit une architecture en couches (Clean Architecture) :

```
langchain/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ application/          # Use cases et facades
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ facades/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ use_cases/
‚îÇ   ‚îú‚îÄ‚îÄ domain/               # Entit√©s et interfaces
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repositories/
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/        # Impl√©mentations concr√®tes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/         # Connexion DB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/           # Mod√®les SQLAlchemy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/     # Impl√©mentations repositories
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frameworks/       # LangChain, embeddings, agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jobs/             # Jobs Celery
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth/             # Validation JWT
‚îÇ   ‚îú‚îÄ‚îÄ interface/            # Controllers et DTOs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dto/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ middleware/
‚îÇ   ‚îî‚îÄ‚îÄ core/                 # Exceptions, logger
‚îú‚îÄ‚îÄ alembic/                  # Migrations de base de donn√©es
‚îî‚îÄ‚îÄ main.py                   # Point d'entr√©e FastAPI
```

### Stack technique

- **Framework** : FastAPI (Python 3.11+)
- **LLM** : LangChain + OpenAI GPT-4
- **Base de donn√©es** : PostgreSQL avec pgvector pour les embeddings
- **Jobs asynchrones** : Celery + Redis
- **Authentification** : JWT (compatible avec NestJS backend)
- **Migrations** : Alembic

## ‚ú® Fonctionnalit√©s

### 1. Analyse de Sentiment

Analyse le sentiment global des retours √©l√®ves pour une mati√®re donn√©e.

### 2. Insights Complets

G√©n√®re des insights structur√©s incluant :

- Th√®mes identifi√©s
- Points positifs et n√©gatifs
- Recommandations actionnables
- Pr√©dictions de risques

### 3. Alertes IA

D√©tecte automatiquement les probl√®mes n√©cessitant une attention imm√©diate.

### 4. R√©sum√©s de Feedback

G√©n√®re des r√©sum√©s textuels (court et d√©taill√©) des retours √©l√®ves via LLM.

### 5. Recherche S√©mantique

Recherche vectorielle dans les r√©ponses des √©l√®ves bas√©e sur la similarit√© s√©mantique.

### 6. Chatbot Intelligent

Agent LangChain capable de r√©pondre aux questions des enseignants en utilisant :

- Analyse de sentiment
- Recherche s√©mantique
- Clustering des r√©ponses

### 7. Rapports Hebdomadaires

G√©n√©ration automatique de rapports hebdomadaires pour chaque organisation (tous les lundis √† 8h).

## üì¶ Pr√©requis

- Python 3.11+
- PostgreSQL 14+ avec l'extension pgvector
- Redis (pour Celery)
- OpenAI API Key

## üöÄ Installation

### 1. Cloner le projet

```bash
cd langchain
```

### 2. Cr√©er un environnement virtuel

```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 4. Installer l'extension pgvector dans PostgreSQL

L'extension pgvector est automatiquement cr√©√©e lors de l'ex√©cution de la migration Alembic.

**Note** : Si vous utilisez Docker avec le `compose.yaml` du backend NestJS, l'image PostgreSQL (`pgvector/pgvector:pg18`) inclut d√©j√† pgvector pr√©install√©. La migration cr√©era automatiquement l'extension dans votre base de donn√©es.

Si vous utilisez PostgreSQL en local (sans Docker), vous devrez installer pgvector au niveau syst√®me :

- **macOS** : `brew install pgvector`
- **Ubuntu/Debian** : `sudo apt-get install postgresql-14-pgvector` (remplacez 14 par votre version)

## ‚öôÔ∏è Configuration

Cr√©er un fichier `.env` √† la racine du projet :

```env
# Environment
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# Database
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/izzzi_ai
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10

# JWT (doit correspondre au backend NestJS)
JWT_SECRET=your-secret-key-here
JWT_ALGORITHM=HS256

# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4-turbo-preview
EMBEDDING_MODEL=text-embedding-3-small

# Redis
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# API
API_V1_PREFIX=/api/v1
CORS_ORIGINS=["http://localhost:3000"]

# Service
SERVICE_NAME=izzzi-ai-service
SERVICE_PORT=8000

# Backend API (pour l'envoi des rapports)
BACKEND_URL=http://localhost:3000
```

## üéÆ Utilisation

### D√©marrer le service

**Option 1 : Utiliser le script de d√©marrage (recommand√©)**

```bash
./start.sh
```

**Option 2 : Lancer manuellement**

```bash
# Activer l'environnement virtuel
source .venv/bin/activate

# Lancer uvicorn
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

Le service sera accessible sur `http://localhost:8000`

> **Note importante** : Assurez-vous toujours que l'environnement virtuel `.venv` est activ√© avant de lancer l'application, sinon vous obtiendrez une erreur `ModuleNotFoundError: No module named 'pydantic_settings'`.

### Documentation API

En mode d√©veloppement, la documentation Swagger est disponible sur :

- Swagger UI : `http://localhost:8000/docs`
- ReDoc : `http://localhost:8000/redoc`

### D√©marrer Celery Worker

```bash
celery -A src.infrastructure.jobs.celery_app worker --loglevel=info
```

### D√©marrer Celery Beat (pour les t√¢ches planifi√©es)

```bash
celery -A src.infrastructure.jobs.celery_app beat --loglevel=info
```

## üì° API Endpoints

### Analysis

- `POST /api/v1/analysis/sentiment` - Analyser le sentiment d'une mati√®re
- `POST /api/v1/analysis/insights/generate` - G√©n√©rer des insights complets
- `POST /api/v1/analysis/subjects/compare` - Comparer plusieurs mati√®res
- `POST /api/v1/analysis/risks/predict` - Pr√©dire les risques

### Feedback

- `GET /api/v1/feedback/subjects/{subject_id}/summary` - Obtenir le r√©sum√© IA
- `GET /api/v1/feedback/subjects/{subject_id}/alerts` - Obtenir les alertes IA
- `POST /api/v1/feedback/subjects/{subject_id}/analyze` - D√©clencher une analyse compl√®te

### Search

- `POST /api/v1/search/semantic` - Recherche s√©mantique dans les r√©ponses

### Chatbot

- `POST /api/v1/chatbot/query` - Poser une question au chatbot intelligent

### Health Check

- `GET /health` - V√©rifier l'√©tat du service

**Note** : Tous les endpoints (sauf `/health` et `/`) n√©cessitent une authentification JWT via le header `Authorization: Bearer <token>`

## üîÑ Jobs Celery

### T√¢ches planifi√©es

1. **Indexation des r√©ponses** (`index_new_responses_task`)

   - Fr√©quence : Toutes les heures
   - Description : Indexe les nouvelles r√©ponses dans le vector store

2. **Analyse quotidienne** (`daily_analysis_task`)

   - Fr√©quence : Tous les jours √† 6h
   - Description : Analyse quotidienne des mati√®res actives

3. **Rapport hebdomadaire** (`weekly_report_task`)
   - Fr√©quence : Tous les lundis √† 8h
   - Description : G√©n√®re et envoie les rapports hebdomadaires aux organisations

### Ex√©cution manuelle

```python
from src.infrastructure.jobs.index_responses import index_new_responses_task
from src.infrastructure.jobs.weekly_report import weekly_report_task

# Ex√©cuter une t√¢che
index_new_responses_task.delay()
weekly_report_task.delay()
```

## üóÑÔ∏è Migrations

### Cr√©er une nouvelle migration

```bash
alembic revision --autogenerate -m "Description de la migration"
```

### Appliquer les migrations

```bash
alembic upgrade head
```

### Revenir en arri√®re

```bash
alembic downgrade -1
```

### Important : Extension pgvector

L'extension `pgvector` doit √™tre activ√©e avant d'appliquer les migrations. Ajoutez cette ligne dans votre premi√®re migration :

```python
def upgrade() -> None:
    op.execute('CREATE EXTENSION IF NOT EXISTS vector')
    # ... reste de la migration
```

### Tables cr√©√©es

Les migrations cr√©ent les tables suivantes :

- `response_embeddings` - Embeddings vectoriels des r√©ponses (pgvector)
- `insights` - Insights g√©n√©r√©s par l'IA (avec colonne embedding optionnelle)
- `analysis_cache` - Cache des analyses
- `subject_analyses` - Analyses par mati√®re
- `chatbot_conversations` - Historique des conversations chatbot

## üß™ D√©veloppement

### Structure des tests

```bash
pytest tests/
```

### Linting

Le projet utilise les standards Python PEP 8.

### Formatage

```bash
black src/
```

## üê≥ Docker

### Build

```bash
docker build -t izzzi-ai-service .
```

### Run

```bash
docker run -p 8000:8000 --env-file .env izzzi-ai-service
```

### Docker Compose

Un fichier `compose.yml` est disponible pour orchestrer le service avec PostgreSQL et Redis.

## üîê Authentification

Le service utilise JWT pour l'authentification. Le token doit √™tre fourni dans le header :

```
Authorization: Bearer <jwt_token>
```

Le format du JWT doit correspondre √† celui g√©n√©r√© par le backend NestJS :

```json
{
  "sub": "user_id",
  "email": "user@example.com",
  "organizationId": "org_id",
  "role": "admin",
  "iat": 1234567890,
  "exp": 1234571490
}
```

## üìä Base de donn√©es

### Mod√®les principaux

- **ResponseEmbeddingModel** : Stocke les embeddings vectoriels des r√©ponses
- **InsightModel** : Insights g√©n√©r√©s avec m√©tadonn√©es
- **SubjectAnalysisModel** : Analyses par mati√®re et p√©riode
- **AnalysisCacheModel** : Cache pour optimiser les performances
- **ChatbotConversationModel** : Historique des conversations

### Recherche vectorielle

Le service utilise pgvector pour la recherche de similarit√©. Les embeddings sont g√©n√©r√©s via OpenAI `text-embedding-3-small` (1536 dimensions).

## üîó Int√©gration avec le Backend

Le service communique avec le backend NestJS via :

1. **R√©ception des requ√™tes** : Le backend appelle les endpoints du service AI
2. **Envoi des rapports** : Le service envoie les rapports hebdomadaires au backend via `POST /v1/reports`

## üìù Notes importantes

- Les embeddings sont g√©n√©r√©s automatiquement lors de l'indexation des r√©ponses
- Le cache est utilis√© pour √©viter de r√©g√©n√©rer les analyses identiques
- Les rapports hebdomadaires sont envoy√©s automatiquement au backend qui se charge de l'envoi d'emails et de notifications push
- L'extension pgvector doit √™tre install√©e dans PostgreSQL avant d'ex√©cuter les migrations

## üêõ D√©pannage

### Erreur "Extension vector does not exist"

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### Erreur de connexion √† la base de donn√©es

V√©rifiez que :

- PostgreSQL est d√©marr√©
- L'URL de connexion dans `.env` est correcte
- L'utilisateur a les permissions n√©cessaires

### Erreur Celery

V√©rifiez que Redis est d√©marr√© et accessible.

## üìÑ Licence

Voir le fichier LICENSE pour plus d'informations.
